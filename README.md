# DS Projen

```sh
# Monorepo directory structure

data-science-projects
├── .github
│   ├── workflows
│   │   ├── code-quality-checks.yaml
│   │   ├── market-intelligence-buybox-predictor.yaml
│   │   ├── niche-insights.yaml
│   │   └── terraform-ci-cd-prod.yml
│   └── CODEOWNERS
├── deployment/
├── docs/
├── domains
│   ├── advertising
│   │   └── .gitkeep
│   ├── advisory
│   │   ├── attribute_analysis/
│   ├── content
│   │   ├── niche-insights/
│   │   └── parallel-flows/
│   ├── demand_generation
│   │   └── .gitkeep
│   ├── forecasting
│   │   └── .gitkeep
│   ├── market_intelligence
│   │   ├── buybox_predictor/
│   └── operations
│       └── .gitkeep
├── .gitignore
├── .pre-commit-config.yaml
├── README.md
├── pyproject.toml
└── run
```


I'd like to create a projen library with the following abstraction:

Should be in `patterninc/ds-projen`

1. A class called Repository which represents the monorepo

    - It should have a list of `MetaflowProject`s

2. A class called `MetaflowProject`, it should have

   - a param `domain: Literal["content", "reference", ...the rest of the domains]` __init__() should fail if the domain entered is not a valid one

   - `project_name: str` e.g. `niche-insights` which would result in it being placed at `domains/content/niche-insights`

   - a method `forecasting_project.add_flow()` with params
    
      - `relative_flow_path: str | Path` e.g. "path/to/some_flow.py" which would result in domains/content/niche-insights/path/to/some_flow.py being created as a sample file aka `domains/{domain}/{project_name}/{rel_fpath}`

      - a param called `runs_in_ci: bool` which causes the flow to be executed in CI (the python flow.py run command)

      - a param called `config_rel_fpath_ci: str | Path | None`
      
      - `config_rel_fpath_non_prod: str | Path | None`

      - `config_rel_fpath_prod: str | Path | None` -- each of these determine which path if any gets passed to `python myflow.py ... --config ./configs/{config_rel_fpath}`. The path is relative to the `./configs/` folder
  

  - The project should have a global `.github/workflows/<domain>-<project name>-ci-cd.yaml` with the following

    - if it's a PR, run tests, linting, projen synth

    <!-- What's a perimeter? What's the difference between prod and non-prod?  -->
    - trigger a deploy to the default perimeter   

    - if it's merge to main, trigger a deploy to the prod perimeter

    - it should deploy all the flows in parallel using a github actions matrix

    - Also, add a workflow_dispatch that allows you manually trigger a deploy to



```python
from ds_projen import MetaflowProject, Repository

# Define the monorepo
repo = Repository(name="data-science-projects")

# Create a project
nlp_project = MetaflowProject(
    domain=DOMAINS.CONTENT,
    project_name="nlp-project",
    import_module_name="nlp_project",   # defaults to project_name replaced with "_"
    python_version="3.11",              # defaults to None, uv will choose it
    dependencies=["numpy", "pandas"],
    dev_dependencies=["pytest", "black"],
    description="A project for NLP tasks",
    authors=[{"name": "Amit", "email": "amit.raj@pattern.com"}],
)

# Add a flow to the project
nlp_project.add_flow(
    relative_flow_path="flow.py",   # relative to the project root
    runs_in_ci=True,
    config_relative_file_path_prod="configs/prod.json",       # used in CI for deploying the flow i.e., creating an Agro workflow
    config_relative_file_path_non_prod="configs/dev.json",    # can be used in CI to test run the flow; flow will run with `--with kubernetes` flag
    config_relative_file_path_ci="configs/dev.json",          # if provided, flow will run in CI with this config
)
# Add gitignore
repo.gitignore.add_patterns(
    "/uv.lock",  # ignore the top-level uv.lock file
    ".metaflow",  # ignore the metaflow folder
    "metaflow.s3.*", # ignore the metaflow.s3 artifacts
    "**/.DS_Store",  # ignore macOS system files
)

# Synthesize the project
repo.synth()
```

```shell
# Setting up a Metaflow Project:

.github/workflows/nlp-project.yaml

domains/content/nlp-project
├── .gitignore
├── configs                  # lazy sample file --  will not be managed by projen after creation
│   └── dev.json
│   └── prod.json
├── nlp_project
│   ├── __init__.py
│   └── module.py
├── sql                     # projen will not create this folder
│   └── sql_file.sql
├── tests
│   └── test__module.py
├── README.md               # lazy sample file --  will not be managed by projen after creation
├── flow.py                 # lazy sample file --  will not be managed by projen after creation
├── pyproject.toml
└── uv.lock                 # Automatically generated by uv -- not managed by projen
```


```toml
# Sample pyproject.toml file
[project]
name = "{{ project_name }}"
version = "{{ version }}"
description = "{{ description }}"
readme = "README.md"
requires-python = " {{ python_version }} "
dependencies = {{ list_of_dependencies }}

[dependency-groups]
dev = {{ list_of_dev_dependencies }}

# adding python path for pytest
[tool.pytest.ini_options]
pythonpath = ["."]
```



```yaml
# Sample workflow file
name: {{ project_name }}-deploy
on:
    workflow_dispatch:
    push:
        branches:
            - main
        paths:
            - '{{ out_dir }}/{{ project_name }}/**'
    pull_request:
        types: [opened, synchronize]
        branches:
            - main
        paths:
            - '{{ out_dir }}/{{ project_name }}/**'

jobs:
    ds-project-deploy:
        name: Deploy {{ project_name }} to Outerbounds
        permissions:
            contents: read
            id-token: write

        env:
            WORKDIR: {{ out_dir }}/{{ project_name }}

        defaults:
          run:
            working-directory: ${{ env.WORKDIR }}

        runs-on: ubuntu-latest
        steps:
            - name: Checkout repository
              uses: actions/checkout@v4

            - name: Set up uv
              uses: astral-sh/setup-uv@v5
              with:
                python-version: '3.11.2'    # Optionally you can set the python version
                enable-cache: true
                cache-dependency-glob: "${{ env.WORKDIR }}/uv.lock"

            - name: Run Tests
              run: uv run pytest tests

            # Optionally you can run the same command with `uvx outerbounds ...`
            # though it's not necessary if outerbounds is your dependency
            - name: Configure Outerbounds
              run: |-
                uv outerbounds service-principal-configure \
                --name github-user-ds-projects \
                --deployment-domain pattern.obp.outerbounds.com \
                --perimeter default \
                --github-actions

            - name: Run a Dev Flow      # Optional Dev Flow
              if: github.ref == 'refs/heads/main' || github.event_name == 'pull_request'
              run: |-
                uv run {{ flow.py }} \
                    --config config {{ dev_config_path }} \
                    --environment=fast-bakery \
                    --package-suffixes='.csv' \
                    run \
                    --tag triggered-from-pr

            - name: Deploy Prod Flow
              if: github.ref == 'refs/heads/main'
              run: |-
                uv run {{ flow.py }} \
                    --config config {{ prod_config_path }} \
                    --environment=fast-bakery \
                    --package-suffixes='.csv' \
                    --production \
                    argo-workflows create
```

